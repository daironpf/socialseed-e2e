# ğŸŒ± socialseed-e2e

[![PyPI](https://img.shields.io/pypi/v/socialseed-e2e)](https://pypi.org/project/socialseed-e2e/)
[![Python](https://img.shields.io/pypi/pyversions/socialseed-e2e)](https://pypi.org/project/socialseed-e2e/)
[![CI](https://github.com/daironpf/socialseed-e2e/workflows/CI/badge.svg)](https://github.com/daironpf/socialseed-e2e/actions)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Downloads](https://img.shields.io/pypi/dm/socialseed-e2e)](https://pypi.org/project/socialseed-e2e/)

> **The ultimate E2E testing framework for REST APIs - Built for developers and AI agents**

**One-liner:** Test your REST APIs with 10x less code using intelligent scaffolding, automatic test discovery, and stateful test chaining. Perfect for both manual testing and AI-generated test suites.

---

## ğŸ“‘ Table of Contents

- [Features](#-key-features)
- [Installation](#-installation)
- [Quick Start](#-quick-start-5-minutes)
- [Hello World Example](#-hello-world-example)
- [Why socialseed-e2e](#-why-socialseed-e2e)
- [Architecture](#-architecture)
- [Advanced Usage](#-advanced-usage)
- [Testing](#-testing)
- [Comparison](#-comparison-with-alternatives)
- [API Documentation](#-api-documentation)
- [Contributing](#-contributing)
- [Roadmap](#-roadmap)
- [License](#-license)

---

## ğŸ¤– Engineered for LLM Reasoning

Traditional testing tools are "token-hungry" because they force AI to handle raw HTTP strings and boilerplate. **socialseed-e2e** introduces a high-level abstraction layer that:

* **Minimizes Token Consumption**: By using structured `IServicePage` protocols, the agent only processes business logic, not implementation noise.
* **Enhanced Contextual Awareness**: Models like **GPT-4o, Claude 3.5, or Mistral Large** can reason about complex API flows and state transitions.
* **Self-Healing Capabilities**: The structured architecture allows the AI to identify and fix broken tests by understanding the underlying service contract.

---

**socialseed-e2e** is a powerful, service-agnostic End-to-End (E2E) testing framework designed to make API testing effortless, scalable, and maintainable. Whether you're a developer writing tests manually or an AI agent generating test suites automatically, this framework provides the perfect foundation for reliable API testing.

## ğŸš€ Why socialseed-e2e?

### For Developers
- **Zero boilerplate**: Start testing in minutes with intelligent scaffolding
- **Playwright-powered**: Rock-solid HTTP testing with browser-like reliability
- **Modular architecture**: Organize tests by service, share state between modules
- **Beautiful CLI**: Rich terminal output with progress bars and detailed reports
- **Type-safe**: Full Pydantic validation and Python type hints

### For AI Agents
- **Structured protocols**: Clear interfaces (`IServicePage`, `ITestModule`) for code generation
- **Auto-discovery**: Tests are automatically found and executed based on directory structure
- **Template system**: Generate consistent test modules with variable substitution
- **Hexagonal architecture**: Core engine is completely decoupled from service logic
- **Configuration-driven**: All settings in YAML/JSON with environment variable support

## âœ¨ Key Features

- ğŸ”¥ **Service-Agnostic Core**: Test any REST API without framework modifications
- ğŸ¯ **Playwright Integration**: Use the same tool for API and UI testing (future-ready)
- ğŸ“ **Smart Scaffolding**: `e2e new-service` and `e2e new-test` commands
- ğŸ” **Auto-Discovery**: No manual test registration required
- ğŸ¨ **Rich CLI Output**: Beautiful terminal reports with tables and progress
- ğŸ”§ **Environment Support**: Dev, staging, production configurations
- ğŸ“Š **Test Orchestration**: Run tests in logical order with proper cleanup
- ğŸ—ï¸ **Hexagonal Architecture**: Clean separation of concerns
- ğŸ¤– **AI-Ready**: Perfect for automated test generation workflows
- ğŸ§ª **Built-in Mock API**: Flask-based mock server for testing without dependencies
- ğŸ“ˆ **Coverage Reports**: Automatic coverage tracking with codecov.io integration

## ğŸ“¦ Installation

```bash
pip install socialseed-e2e
playwright install chromium
```

For development:
```bash
git clone https://github.com/daironpf/socialseed-e2e.git
cd socialseed-e2e
pip install -e ".[dev]"
playwright install chromium
```

## ğŸƒ Quick Start (5 minutes)

### 1. Initialize Your Project

```bash
e2e init my-api-tests
cd my-api-tests
```

This creates:
```
my-api-tests/
â”œâ”€â”€ e2e.conf          # Configuration file
â”œâ”€â”€ services/         # Service test implementations
â””â”€â”€ tests/           # Test modules
```

### 2. Configure Your API

Edit `e2e.conf`:

```yaml
general:
  environment: dev
  timeout: 30000
  verbose: true

services:
  users-api:
    name: users-service
    base_url: http://localhost:8080
    health_endpoint: /health
    timeout: 5000
    required: true
```

### 3. Create Your First Service

```bash
e2e new-service users-api
```

Generates:
```
services/
â””â”€â”€ users-api/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ users_api_page.py      # Service page class
    â”œâ”€â”€ data_schema.py         # DTOs and constants
    â””â”€â”€ modules/               # Test modules
        â””â”€â”€ __init__.py
```

### 4. Create a Test Module

```bash
e2e new-test login --service users-api
```

This creates `services/users-api/modules/01_login_flow.py`:

```python
from playwright.sync_api import APIResponse
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from ..users_api_page import UsersApiPage

def run(users_api: 'UsersApiPage') -> APIResponse:
    """
    Test user login flow.
    
    Args:
        users_api: Instance of UsersApiPage
    
    Returns:
        APIResponse: HTTP response
    """
    print("Running login test...")
    
    # Arrange
    credentials = {"email": "test@example.com", "password": "secret123"}
    
    # Act
    response = users_api.post("/auth/login", json=credentials)
    
    # Assert
    if response.ok:
        data = response.json()
        users_api.auth_token = data["token"]  # Share state!
        print(f"âœ“ Login successful! Token: {data['token'][:20]}...")
    else:
        print(f"âœ— Login failed: {response.status}")
        raise AssertionError(f"Expected 200, got {response.status}")
    
    return response
```

### 5. Run Your Tests

```bash
e2e run
```

Output:
```
ğŸš€ socialseed-e2e v0.1.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Configuration: e2e.conf
ğŸŒ Environment: dev

ğŸ” Discovering services...
âœ“ Found 1 service: users-api

ğŸ“¦ Service: users-api
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ§ª Running 1 test module(s)

[1/1] 01_login_flow.py
Running login test...
âœ“ Login successful! Token: eyJhbGciOiJIUzI1Ni...
âœ“ PASSED

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… All tests passed! (1/1)
â±ï¸  Duration: 0.42s

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ‰ Test run completed successfully!
```

## ğŸ‘‹ Hello World Example

The simplest possible test with socialseed-e2e:

```python
# services/my-api/modules/01_hello_world.py
def run(api):
    """Test that our API is alive."""
    response = api.get("/health")
    assert response.status == 200
    print("âœ“ API is healthy!")
    return response
```

That's it! 5 lines of code vs 30+ lines with traditional testing tools.

**What you get for free:**
- âœ… Automatic retry with exponential backoff
- âœ… Rate limiting protection
- âœ… Request/response logging
- âœ… Beautiful terminal output
- âœ… State sharing between tests
- âœ… Error handling and reporting

## ğŸ—ï¸ Architecture

### High-Level Flow

```mermaid
graph TD;
    subgraph "AI Agent Layer"
        A[AI Agent / LLM] -- "Generates/Heals" --> B[Test Modules]
    end
    
    subgraph "SocialSeed E2E Framework"
        B -- "Uses" --> C[Service Page Classes]
        C -- "Extends" --> D[Core BasePage]
        D -- "Orchestrates" --> E[Playwright Engine]
    end
    
    subgraph "Target Infrastructure"
        E -- "REST / JSON" --> F[Microservices]
    end
    
    G[YAML/JSON Config] -.-> D
```

```
socialseed-e2e/
â”œâ”€â”€ core/                    # Service-agnostic engine
â”‚   â”œâ”€â”€ base_page.py        # HTTP abstraction layer
â”‚   â”œâ”€â”€ config_loader.py    # Configuration management
â”‚   â”œâ”€â”€ test_orchestrator.py # Test discovery & execution
â”‚   â”œâ”€â”€ interfaces.py       # Protocols for AI/codegen
â”‚   â””â”€â”€ loaders.py          # Dynamic module loading
â”œâ”€â”€ services/               # Your service implementations
â”‚   â””â”€â”€ users-api/
â”‚       â”œâ”€â”€ users_api_page.py
â”‚       â”œâ”€â”€ data_schema.py
â”‚       â””â”€â”€ modules/
â”‚           â”œâ”€â”€ 01_login_flow.py
â”‚           â”œâ”€â”€ 02_register_flow.py
â”‚           â””â”€â”€ 03_profile_flow.py
â””â”€â”€ templates/              # Scaffolding templates
```

## ğŸ¨ Advanced Usage

### Chaining Tests with Shared State

```python
# 01_create_user_flow.py
def run(users_api: 'UsersApiPage') -> APIResponse:
    response = users_api.post("/users", json={"name": "John"})
    users_api.current_user = response.json()  # Store for next test
    return response

# 02_update_user_flow.py
def run(users_api: 'UsersApiPage') -> APIResponse:
    user_id = users_api.current_user["id"]  # Access from previous test
    return users_api.put(f"/users/{user_id}", json={"name": "Jane"})
```

### Running Specific Services

```bash
# Run all tests
e2e run

# Run specific service
e2e run --service users-api

# Run specific module
e2e run --service users-api --module login

# Verbose output
e2e run --verbose
```

### Environment-Specific Configuration

```bash
# Use different config files
E2E_CONFIG_PATH=e2e.prod.conf e2e run

# Or use environment variables in config
services:
  api:
    base_url: ${API_BASE_URL:-http://localhost:8080}
```

## ğŸ§ª Testing

The framework includes a comprehensive test suite with **420+ tests** organized for maintainability:

### Test Organization

```
tests/
â”œâ”€â”€ unit/                      # Unit tests for core components
â”‚   â”œâ”€â”€ test_base_page.py     # HTTP client tests
â”‚   â”œâ”€â”€ test_config_loader.py # Configuration tests
â”‚   â”œâ”€â”€ test_loaders.py       # Module loader tests
â”‚   â”œâ”€â”€ test_orchestrator.py  # Test orchestration tests
â”‚   â”œâ”€â”€ test_template_engine.py # Template system tests
â”‚   â”œâ”€â”€ test_validators.py    # Validation helper tests
â”‚   â””â”€â”€ test_imports_compatibility.py # Import system tests
â”‚
â””â”€â”€ integration/               # Integration tests
    â””â”€â”€ cli/                   # CLI command tests (organized by command)
        â”œâ”€â”€ test_init.py       # 'e2e init' tests
        â”œâ”€â”€ test_new_service.py # 'e2e new-service' tests
        â”œâ”€â”€ test_new_test.py   # 'e2e new-test' tests
        â”œâ”€â”€ test_run.py        # 'e2e run' tests
        â”œâ”€â”€ test_doctor.py     # 'e2e doctor' tests
        â”œâ”€â”€ test_config.py     # 'e2e config' tests
        â”œâ”€â”€ test_error_handling.py # Error handling tests
        â””â”€â”€ test_workflows.py  # End-to-end workflows
```

### Running Tests

```bash
# Run all tests
pytest

# Run unit tests only
pytest tests/unit/
# Or using markers:
pytest -m unit

# Run integration tests
pytest tests/integration/
# Or using markers:
pytest -m integration

# Run CLI integration tests
pytest tests/integration/cli/
# Or using markers:
pytest -m cli

# Run tests for specific command
pytest tests/integration/cli/test_init.py

# Run with coverage report (minimum 80%)
pytest --cov=socialseed_e2e --cov-report=html

# Run excluding slow tests
pytest -m "not slow"

# Run specific marker combinations
pytest -m "unit and not slow"
```

**Available Test Markers:**
- `@pytest.mark.unit` - Fast, isolated unit tests
- `@pytest.mark.integration` - Integration tests
- `@pytest.mark.slow` - Long-running tests
- `@pytest.mark.cli` - CLI command tests
- `@pytest.mark.mock_api` - Tests using the mock Flask API

**Coverage Reports:** Automatically uploaded to [codecov.io](https://codecov.io/gh/daironpf/socialseed-e2e) on each CI run (minimum 80% coverage required).

ğŸ“š **Detailed testing documentation:** [docs/testing-guide.md](docs/testing-guide.md)

### Mock API for Integration Testing

The framework includes a built-in **Flask-based Mock API** for testing without external dependencies:

```bash
# Start the mock API server
python tests/fixtures/mock_api.py
```

**Features:**
- Health check endpoint (`GET /health`)
- Complete user CRUD operations (`/api/users`)
- Authentication system (`/api/auth/login`, `/api/auth/register`)
- Pre-seeded test data (admin and user accounts)
- Pytest fixtures for automated testing

**Quick Test with Mock API:**
```python
def test_health(mock_api_url):
    response = requests.get(f"{mock_api_url}/health")
    assert response.status_code == 200
```

**Available Fixtures:**
- `mock_api_url` - Base URL (http://localhost:8765)
- `mock_api_reset` - Reset data before each test
- `sample_user_data` - Sample user data
- `admin_credentials` / `user_credentials` - Pre-configured accounts

ğŸ“š **Full documentation:** [tests/fixtures/README.md](tests/fixtures/README.md)  
ğŸ“– **For AI Agents:** [docs/mock-api.md](docs/mock-api.md) - Detailed guide with patterns and best practices

## ğŸ§© Comparison with Alternatives

| Feature | socialseed-e2e | Postman | pytest + requests | Karate |
|---------|---------------|---------|-------------------|--------|
| **Code-based** | âœ… Python | âŒ GUI/JavaScript | âœ… Python | âŒ Java/Gherkin |
| **Test Chaining** | âœ… Stateful | âŒ Manual | âš ï¸ DIY | âœ… Built-in |
| **Auto Discovery** | âœ… Yes | âŒ Manual | âŒ Manual | âœ… Yes |
| **CLI Tool** | âœ… Rich CLI | âš ï¸ Newman | âŒ DIY | âœ… Yes |
| **Scaffolding** | âœ… Yes | âŒ No | âŒ No | âš ï¸ Templates |
| **AI-Ready** | âœ… Designed for AI | âŒ No | âŒ No | âŒ No |
| **Mock API** | âœ… Built-in | âŒ Separate | âŒ DIY | âš ï¸ Limited |
| **Coverage** | âœ… Built-in | âŒ No | âš ï¸ Plugin | âŒ No |
| **Type Safety** | âœ… Pydantic | âŒ No | âš ï¸ Optional | âŒ No |
| **Learning Curve** | ğŸŸ¢ Low | ğŸŸ¢ Low | ğŸŸ¡ Medium | ğŸŸ¡ Medium |

**When to use socialseed-e2e:**
- You want **10x less code** than traditional approaches
- You need **stateful test chaining** across multiple API calls
- You're building **AI-generated test suites**
- You want a **CLI-first** workflow
- You need **built-in mocking** without external dependencies
- You want **professional-grade reporting** out of the box

**When to use alternatives:**
- **Postman**: Best for manual API exploration and quick one-off tests
- **pytest + requests**: Best when you need full control and custom logic
- **Karate**: Best for teams already using JVM ecosystem

## ğŸ“š API Documentation

- **[Installation Guide](docs/installation.md)** - Detailed installation instructions
- **[Quick Start](docs/quickstart.md)** - Get up and running in 15 minutes
- **[Configuration](docs/configuration.md)** - e2e.conf options and examples
- **[Writing Tests](docs/writing-tests.md)** - Test writing patterns and best practices
- **[CLI Reference](docs/cli-reference.md)** - Complete CLI command reference
- **[API Reference](docs/api-reference.md)** - Framework API documentation
- **[Testing Guide](docs/testing-guide.md)** - Pytest configuration and test execution
- **[Mock API](docs/mock-api.md)** - Using the built-in Flask mock API

## ğŸ¤ Contributing

We welcome contributions from developers and AI agents! Please read our:

ğŸ“‹ **[Contributing Guidelines](CONTRIBUTING.md)** - How to contribute code, report bugs, and suggest features  
ğŸ¤– **[AGENTS.md](AGENTS.md)** - Special guide for AI agents contributing to this project  
ğŸ“œ **[AI_CONTRIBUTORS.md](AI_CONTRIBUTORS.md)** - Recognition for AI agent contributions

### Quick Contribution Steps

```bash
# Fork and clone
git clone https://github.com/daironpf/socialseed-e2e.git
cd socialseed-e2e

# Install dev dependencies
pip install -e ".[dev]"

# Run tests
pytest

# Make changes and run tests again
pytest

# Submit PR
```

### Development Commands

```bash
# Run tests
pytest

# Run only unit tests
pytest tests/unit/

# Run only integration tests
pytest tests/integration/

# Run with coverage
pytest --cov=socialseed_e2e --cov-report=html

# Run linting
black src/ tests/
flake8 src/ tests/
mypy src/socialseed_e2e
```

## ğŸš¦ Project Status

- âœ… **Core Framework**: Complete and tested
- âœ… **CLI Commands**: init, new-service, new-test, run, doctor, config
- âœ… **Configuration**: YAML/JSON with environment variables
- âœ… **Mock API**: Flask-based server for integration testing
- âœ… **CI/CD**: GitHub Actions configured
- ğŸš§ **HTML Reports**: In development
- ğŸš§ **Parallel Execution**: In development
- ğŸ“‹ **Plugin System**: Planned

---

## âš¡ Seeking API Partnerships

**socialseed-e2e** is currently in a high-growth phase, focusing on **Autonomous Self-Healing Tests**. Due to geographic and resource constraints, we are actively looking for **API Credits or Partnerships** (OpenAI, Anthropic, Google Cloud, Mistral) to stress-test our reasoning engine with large-scale microservice architectures.

> [!TIP]
> **If you represent an AI provider** and want to see your model as the default engine for AI-native E2E testing, we would love to collaborate. Let's push the boundaries of autonomous engineering together.

## ğŸ—ºï¸ Roadmap

### v0.1.0 (Current)
- âœ… Core framework
- âœ… Basic CLI
- âœ… Configuration system
- âœ… Mock API server

### v0.2.0 (Next)
- ğŸš§ HTML reports with detailed metrics
- ğŸš§ Parallel test execution
- ğŸš§ Better authentication handling
- ğŸš§ WebSocket support

### v0.3.0 (Planned)
- ğŸ“‹ Plugin system for custom extensions
- ğŸ“‹ Docker integration
- ğŸ“‹ Visual regression testing
- ğŸ“‹ Performance testing metrics

### v0.4.0 (Future)
- ğŸ“‹ WebSocket support
- ğŸ“‹ GraphQL support
- ğŸ“‹ gRPC testing support
- ğŸ“‹ AI-powered test healing

## ğŸ’¬ Community

- **GitHub Discussions**: [Join the conversation](https://github.com/daironpf/socialseed-e2e/discussions)
- **Issues**: [Report bugs or request features](https://github.com/daironpf/socialseed-e2e/issues)

## â­ Star Us!

If you find socialseed-e2e helpful, please give us a star on GitHub! It helps others discover the project and motivates continued development.

```bash
# Star the repo
git clone https://github.com/daironpf/socialseed-e2e.git
cd socialseed-e2e
# Then click the â­ star button!
```

## ğŸ¤– AI Contributors

This project recognizes AI agents as legitimate co-authors. Current AI contributors:

- **[OpenCode AI Agent](https://github.com/anomalyco)** - Framework architecture, core implementation, test suite
- **Claude (Anthropic)** - Documentation, feature suggestions, bug fixes

See [AI_CONTRIBUTORS.md](AI_CONTRIBUTORS.md) for full details.

## ğŸ’ Acknowledgments

- **Playwright team** for the amazing HTTP testing engine
- **Pydantic team** for type-safe data validation
- **Rich team** for beautiful terminal output
- **All contributors** who have helped improve this project

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) file for details.

---

<p align="center">
  <b>Built with â¤ï¸ by developers, for developers and AI agents</b>
</p>
